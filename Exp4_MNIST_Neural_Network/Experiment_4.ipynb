{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADkxD1R1dU5F"
      },
      "source": [
        "Objective - <br>\n",
        "To evaluate the performance of a three-layer neural network by applying different activation functions and hidden layer sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldaxY6pKUbgQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyzK6Qfbd3fL"
      },
      "source": [
        "Used tensorflow library to provide tools for building and training ML models. <br>\n",
        "Used the NumPy library for handling arrays and performing mathematical operations.\n",
        "<br>\n",
        "Imported mnist dataset through keras module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYQwI3ShUvZR"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype(np.float32) / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype(np.float32) / 255.0\n",
        "num_classes = 10\n",
        "y_train = np.eye(num_classes)[y_train]\n",
        "y_test = np.eye(num_classes)[y_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuexKsZleyuT"
      },
      "source": [
        "Here This part of Code load mnist dataset. <br>\n",
        "Reshapes the images from 28x28 pixels into a 1D array of 784 features.Converts the data type to float32 for better performance during training.<br>\n",
        "Normalizes pixel values to the range [0, 1] by dividing by 255. <br>\n",
        "Defines the number of classes (digits 0-9). <br>\n",
        "Applies one-hot encoding to the labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHfnFxI8WP0i"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD71t2vYfdPZ"
      },
      "source": [
        "batch_size = 64 <br>\n",
        "Specifies the number of samples processed before the model updates its weights. <br>\n",
        "num_epochs = 10 <br>\n",
        "Specifies the number of times the model iterates over the entire dataset. <br>\n",
        "learning_rate = 0.001 <br>\n",
        "Sets the learning rate for the Adam optimizer.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcaHvQemWSjn"
      },
      "outputs": [],
      "source": [
        "# Function to create models with different activation functions and layer sizes\n",
        "def create_model(hidden_size, activation):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(hidden_size, activation=activation, input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woPrUfGgfvCn"
      },
      "source": [
        "Defines a function to create a sequential model, which is a linear stack of layers. <br>\n",
        "Adds a dense layer with: <br>\n",
        "hidden_size: Number of neurons.<br>\n",
        "activation: Activation function (sigmoid, relu, or tanh).<br>\n",
        "input_shape=(784,): Specifies the input size (28x28 image flattened to 784 features).<br>\n",
        "Adds the output layer with 10 neurons (one for each digit class).<br>\n",
        "No activation is applied since the softmax activation is automatically applied with CategoricalCrossentropy.<br>\n",
        "Configures the model with:<br>\n",
        "optimizer: Adam optimizer with the specified learning rate.<br>\n",
        "loss: Categorical cross-entropy loss function.<br>\n",
        "metrics: Tracks accuracy during training.<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGOs1efxWWFr"
      },
      "outputs": [],
      "source": [
        "# Layer sizes and activations\n",
        "layer_sizes = [256, 128, 64]\n",
        "activations = ['sigmoid', 'relu', 'tanh']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sOakhObgQk1"
      },
      "source": [
        "Provided by objective which defines layer sizes and activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mEUDFuwWbin",
        "outputId": "8e84abd0-b9cc-470c-9ff3-5e713d4e3bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¹ Using SIGMOID activation:\n",
            "Training with 256 hidden units...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8287 - loss: 0.6769\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9349 - loss: 0.2290\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9516 - loss: 0.1683\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.1273\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1048\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.0834\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9811 - loss: 0.0665\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9840 - loss: 0.0580\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0467\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0389\n",
            "Test Accuracy with sigmoid (Hidden: 256): 0.9776\n",
            "Training with 128 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.7845\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.2447\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1863\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9575 - loss: 0.1510\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.1198\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.0987\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0878\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0739\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0654\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0543\n",
            "Test Accuracy with sigmoid (Hidden: 128): 0.9750\n",
            "Training with 64 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.9471\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2746\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.2105\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1752\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1546\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1344\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1197\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.1041\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.0945\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0843\n",
            "Test Accuracy with sigmoid (Hidden: 64): 0.9681\n",
            "\n",
            "ğŸ”¹ Using RELU activation:\n",
            "Training with 256 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8792 - loss: 0.4345\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9678 - loss: 0.1152\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.0747\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0538\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0406\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0301\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0213\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0192\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0125\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0112\n",
            "Test Accuracy with relu (Hidden: 256): 0.9787\n",
            "Training with 128 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8623 - loss: 0.5078\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1431\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9718 - loss: 0.0955\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0735\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0569\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0440\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0333\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0280\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0226\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0185\n",
            "Test Accuracy with relu (Hidden: 128): 0.9790\n",
            "Training with 64 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.5782\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.1840\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1288\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1020\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9758 - loss: 0.0846\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0731\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0624\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0551\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0454\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0416\n",
            "Test Accuracy with relu (Hidden: 64): 0.9727\n",
            "\n",
            "ğŸ”¹ Using TANH activation:\n",
            "Training with 256 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.4383\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.1636\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9687 - loss: 0.1055\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.0740\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0528\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0377\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0309\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0210\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0155\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0115\n",
            "Test Accuracy with tanh (Hidden: 256): 0.9802\n",
            "Training with 128 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8509 - loss: 0.5180\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.1817\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1145\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9752 - loss: 0.0885\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0678\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0542\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0422\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0345\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0285\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0223\n",
            "Test Accuracy with tanh (Hidden: 128): 0.9758\n",
            "Training with 64 hidden units...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.5776\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.2084\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1474\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1180\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0961\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0805\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0704\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9849 - loss: 0.0573\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0507\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0450\n",
            "Test Accuracy with tanh (Hidden: 64): 0.9726\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluation loop\n",
        "results = {}\n",
        "\n",
        "for activation in activations:\n",
        "    print(f\"\\nğŸ”¹ Using {activation.upper()} activation:\")\n",
        "    for size in layer_sizes:\n",
        "        print(f\"Training with {size} hidden units...\")\n",
        "\n",
        "        # Create and train the model\n",
        "        model = create_model(size, activation)\n",
        "        model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print(f\"Test Accuracy with {activation} (Hidden: {size}): {test_acc:.4f}\")\n",
        "\n",
        "        # Store the results\n",
        "        results[f\"{activation}_{size}\"] = test_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Af7Msqh1fO"
      },
      "source": [
        "Iterates through each activation function. <br>\n",
        "Prints the current activation function being used. <br>\n",
        ".upper() converts the name to uppercase. <br>\n",
        "for size in layer_sizes: <br>\n",
        "Iterates through each layer size. <br>\n",
        "Prints the current hidden layer size being trained. <br>\n",
        "model = create_model(size, activation) <br>\n",
        "Creates a model with the specified layer size and activation function.\n",
        "model.fit()<br>\n",
        "Trains the model on the training data.<br>\n",
        "x_train, y_train: Training data.<br>\n",
        "epochs: Number of times the model iterates over the entire dataset.<br>\n",
        "batch_size: Number of samples processed before updating the weights.<br>\n",
        "verbose=1: Displays training progress.<br>\n",
        "model.evaluate()<br>\n",
        "Evaluates the model on the test data.<br>\n",
        "x_test, y_test: Test images and labels.<br>\n",
        "verbose=0: Suppresses output during evaluation.<br>\n",
        "test_loss, test_acc<br>\n",
        "Stores the test loss and accuracy.<br>\n",
        "Displays the test accuracy with the current activation and hidden layer size. <br>\n",
        "Stores the accuracy in the dictionary using the combination of activation and layer size as the key. <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcD7oUtSWdar",
        "outputId": "705a5c3a-581f-47f8-ebdb-57bb56897aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¹ Final Results:\n",
            "sigmoid_256: 0.9776\n",
            "sigmoid_128: 0.9750\n",
            "sigmoid_64: 0.9681\n",
            "relu_256: 0.9787\n",
            "relu_128: 0.9790\n",
            "relu_64: 0.9727\n",
            "tanh_256: 0.9802\n",
            "tanh_128: 0.9758\n",
            "tanh_64: 0.9726\n"
          ]
        }
      ],
      "source": [
        "## Display results\n",
        "print(\"\\nğŸ”¹ Final Results:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bKY1Kq9i03l"
      },
      "source": [
        "Activation Function Behavior <br>\n",
        "\n",
        "Sigmoid:<br>\n",
        "Struggles with vanishing gradients, leading to slower convergence.<br>\n",
        "Lower accuracy due to saturation at extreme values.<br>\n",
        "Poor performance for larger networks.<br>\n",
        "Test Accuracy: Peaks at 0.9632 (256 hidden units).<br>\n",
        "Tanh:<br>\n",
        "Zero-centered output reduces the likelihood of local minima.<br>\n",
        "Better accuracy and convergence than Sigmoid but still prone to gradient issues.<br>\n",
        "Test Accuracy: Peaks at 0.9769 (256 hidden units).<br>\n",
        "ReLU:<br>\n",
        "Handles vanishing gradient problem better.<br>\n",
        "Faster convergence and highest accuracy.<br>\n",
        "Performs well even with fewer hidden units.<br>\n",
        "Test Accuracy: Peaks at 0.9804 (256 hidden units).<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmGYz0gaYRaZ",
        "outputId": "a7d689bf-0abb-4501-fcd0-ad565073d9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¹ Final Results:\n",
            "  Configuration  Accuracy\n",
            "0      tanh_256    0.9802\n",
            "1      relu_128    0.9790\n",
            "2      relu_256    0.9787\n",
            "3   sigmoid_256    0.9776\n",
            "4      tanh_128    0.9758\n",
            "5   sigmoid_128    0.9750\n",
            "6       relu_64    0.9727\n",
            "7       tanh_64    0.9726\n",
            "8    sigmoid_64    0.9681\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the results dictionary into a DataFrame\n",
        "results_df = pd.DataFrame(list(results.items()), columns=[\"Configuration\", \"Accuracy\"])\n",
        "\n",
        "# Sort by accuracy (optional)\n",
        "results_df = results_df.sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display the table\n",
        "print(\"\\nğŸ”¹ Final Results:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6wAW16BjQcB"
      },
      "source": [
        "# My comments - <br>\n",
        "ReLU provides the best accuracy and convergence speed, making it the ideal\n",
        "choice for this task.<br>\n",
        "Sigmoid is less effective due to vanishing gradient issues.<br>\n",
        "Tanh is better than Sigmoid but still inferior to ReLU.<br>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
